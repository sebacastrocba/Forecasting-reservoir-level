{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined model: hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from sklearn.base import TransformerMixin, BaseEstimator, RegressorMixin\n",
    "from feature_engine.creation import CyclicalFeatures\n",
    "from feature_engine.datetime import DatetimeFeatures\n",
    "from feature_engine.imputation import DropMissingData\n",
    "from feature_engine.selection import DropFeatures\n",
    "from feature_engine.timeseries.forecasting import (\n",
    "    LagFeatures,\n",
    "    WindowFeatures,\n",
    ")\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "#from hybrid_regressor import CombinedRegressor, LinearBoost\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "from mizani.breaks import date_breaks\n",
    "from plotnine import *\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre_embalse</th>\n",
       "      <th>cota</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01 04:00:00+00:00</th>\n",
       "      <td>ANGOSTURA</td>\n",
       "      <td>316.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 05:00:00+00:00</th>\n",
       "      <td>ANGOSTURA</td>\n",
       "      <td>316.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 06:00:00+00:00</th>\n",
       "      <td>ANGOSTURA</td>\n",
       "      <td>316.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 07:00:00+00:00</th>\n",
       "      <td>ANGOSTURA</td>\n",
       "      <td>316.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 08:00:00+00:00</th>\n",
       "      <td>ANGOSTURA</td>\n",
       "      <td>316.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-28 11:00:00+00:00</th>\n",
       "      <td>RAPEL</td>\n",
       "      <td>103.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-28 12:00:00+00:00</th>\n",
       "      <td>RAPEL</td>\n",
       "      <td>103.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-28 13:00:00+00:00</th>\n",
       "      <td>RAPEL</td>\n",
       "      <td>103.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-28 14:00:00+00:00</th>\n",
       "      <td>RAPEL</td>\n",
       "      <td>103.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-28 15:00:00+00:00</th>\n",
       "      <td>RAPEL</td>\n",
       "      <td>103.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113040 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          nombre_embalse    cota\n",
       "timestamp                                       \n",
       "2022-01-01 04:00:00+00:00      ANGOSTURA  316.42\n",
       "2022-01-01 05:00:00+00:00      ANGOSTURA  316.42\n",
       "2022-01-01 06:00:00+00:00      ANGOSTURA  316.44\n",
       "2022-01-01 07:00:00+00:00      ANGOSTURA  316.45\n",
       "2022-01-01 08:00:00+00:00      ANGOSTURA  316.46\n",
       "...                                  ...     ...\n",
       "2023-01-28 11:00:00+00:00          RAPEL  103.72\n",
       "2023-01-28 12:00:00+00:00          RAPEL  103.72\n",
       "2023-01-28 13:00:00+00:00          RAPEL  103.72\n",
       "2023-01-28 14:00:00+00:00          RAPEL  103.72\n",
       "2023-01-28 15:00:00+00:00          RAPEL  103.72\n",
       "\n",
       "[113040 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reservoir_hourly = pd.read_csv('../data/processed/reservoir_data_hourly.csv', parse_dates=['timestamp'])\n",
    "reservoir_hourly = reservoir_hourly.set_index('timestamp')\n",
    "reservoir_hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly detection and removal\n",
    "def detect_outliers(df, value_col, period = None, robust = True):\n",
    "    serie = df[value_col]\n",
    "    res = STL(serie, period = period, robust = robust).fit()\n",
    "    resid = res.resid\n",
    "    q1 = resid.quantile(0.25)\n",
    "    q3 = resid.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - (3*iqr)\n",
    "    upper = q3 + (3*iqr)\n",
    "\n",
    "    anomalies = serie[(resid < lower) | (resid >= upper)]\n",
    "    df = df.assign(anomaly = np.where(df[value_col].index.isin(anomalies.index), 1, 0))\n",
    "    df[\"value_corrected\"] = np.where(df[\"anomaly\"] == True, np.NaN, df[value_col])\n",
    "    df.interpolate(method = \"linear\", inplace=True)\n",
    "    df[\"value_corrected\"] = np.where(df[\"value_corrected\"].isna(), df[value_col], df[\"value_corrected\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reservoir_list = reservoir_hourly[\"nombre_embalse\"].unique()\n",
    "\n",
    "emb_df_list = list()\n",
    "emb_df_anomalies_list = list()\n",
    "for emb in reservoir_list:\n",
    "    emb_df = reservoir_hourly[reservoir_hourly[\"nombre_embalse\"] == emb]\n",
    "    emb_df = emb_df.asfreq(\"H\")\n",
    "    emb_df = emb_df.sort_index()\n",
    "    \n",
    "    emb_df_sin_outliers = detect_outliers(emb_df, \"cota\", robust=True)\n",
    "    emb_df_list.append(emb_df_sin_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre_embalse</th>\n",
       "      <th>cota</th>\n",
       "      <th>anomaly</th>\n",
       "      <th>value_corrected</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01 04:00:00+00:00</th>\n",
       "      <td>ANGOSTURA</td>\n",
       "      <td>316.42</td>\n",
       "      <td>0</td>\n",
       "      <td>316.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 05:00:00+00:00</th>\n",
       "      <td>ANGOSTURA</td>\n",
       "      <td>316.42</td>\n",
       "      <td>0</td>\n",
       "      <td>316.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 06:00:00+00:00</th>\n",
       "      <td>ANGOSTURA</td>\n",
       "      <td>316.44</td>\n",
       "      <td>0</td>\n",
       "      <td>316.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 07:00:00+00:00</th>\n",
       "      <td>ANGOSTURA</td>\n",
       "      <td>316.45</td>\n",
       "      <td>0</td>\n",
       "      <td>316.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 08:00:00+00:00</th>\n",
       "      <td>ANGOSTURA</td>\n",
       "      <td>316.46</td>\n",
       "      <td>0</td>\n",
       "      <td>316.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          nombre_embalse    cota  anomaly  value_corrected\n",
       "timestamp                                                                 \n",
       "2022-01-01 04:00:00+00:00      ANGOSTURA  316.42        0           316.42\n",
       "2022-01-01 05:00:00+00:00      ANGOSTURA  316.42        0           316.42\n",
       "2022-01-01 06:00:00+00:00      ANGOSTURA  316.44        0           316.44\n",
       "2022-01-01 07:00:00+00:00      ANGOSTURA  316.45        0           316.45\n",
       "2022-01-01 08:00:00+00:00      ANGOSTURA  316.46        0           316.46"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned = pd.concat(emb_df_list, axis = 0)\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = data_cleaned.drop(['cota', 'anomaly'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation split\n",
    "val_len = 24 # one day\n",
    "in_sample_df = data_cleaned.groupby(\"nombre_embalse\", group_keys=False).apply(lambda x : x.iloc[:-val_len, :])\n",
    "out_of_sample_df = data_cleaned.groupby(\"nombre_embalse\", group_keys=False).apply(lambda x : x.iloc[-val_len:, :])\n",
    "\n",
    "in_sample_df = in_sample_df.reset_index()\n",
    "out_of_sample_df = out_of_sample_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "test_time = pd.Timedelta(24*7*4, unit = \"H\")\n",
    "split_point = in_sample_df[\"timestamp\"].max() - test_time\n",
    "\n",
    "X_train = in_sample_df[in_sample_df[\"timestamp\"] < split_point]\n",
    "X_test = in_sample_df[in_sample_df[\"timestamp\"] >= split_point - pd.Timedelta(24*4, unit = \"H\")]\n",
    "\n",
    "y_train = in_sample_df[in_sample_df[\"timestamp\"] < split_point][[\"timestamp\",\"nombre_embalse\",\"value_corrected\"]]\n",
    "y_test = in_sample_df[in_sample_df[\"timestamp\"] >= split_point - pd.Timedelta(24*4, unit = \"H\")][[\"timestamp\", \"nombre_embalse\", \"value_corrected\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.set_index([\"timestamp\", \"nombre_embalse\"])\n",
    "X_test = X_test.set_index([\"timestamp\", \"nombre_embalse\"])\n",
    "y_train = y_train.set_index([\"timestamp\", \"nombre_embalse\"])\n",
    "y_test = y_test.set_index([\"timestamp\", \"nombre_embalse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourier Features Class\n",
    "class AddFourierFeatures(BaseEstimator, TransformerMixin):\n",
    "    seconds_per_day = 24*60*60     # Daily dataset\n",
    "    seconds_per_hour = 60*60       # Hourly dataset\n",
    "\n",
    "    def __init__(self, K, periods: list, by = \"day\"):\n",
    "        self.K = K\n",
    "        self.periods = periods\n",
    "        self.by = by\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        dates = X.index\n",
    "        \n",
    "        for period in self.periods:\n",
    "            term = self.K / period\n",
    "            timestamps = dates.map(datetime.datetime.timestamp)\n",
    "            ts_scaled = []\n",
    "\n",
    "            for ts in timestamps:\n",
    "                if self.by == \"day\":\n",
    "                    x_scaled = round(ts / self.seconds_per_day)\n",
    "                    ts_scaled.append(x_scaled)\n",
    "                else:\n",
    "                    x_scaled = round(ts / self.seconds_per_hour)\n",
    "                    ts_scaled.append(x_scaled)\n",
    "\n",
    "            X[\"fourier_sin\"] = [np.sin(2 * np.pi * term * ts) for ts in ts_scaled]\n",
    "            X[\"fourier_cos\"] = [np.cos(2 * np.pi * term * ts) for ts in ts_scaled]\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers\n",
    "horizon = 24\n",
    "\n",
    "dtf = DatetimeFeatures(\n",
    "    variables=\"index\",\n",
    "    features_to_extract=[\n",
    "        \"hour\",\n",
    "        \"day_of_month\",\n",
    "        \"month\",\n",
    "        \"year\",\n",
    "        \"day_of_year\",\n",
    "        \"week\",\n",
    "        \"day_of_week\",\n",
    "        \"weekend\"\n",
    "    ],\n",
    "    drop_original = False,\n",
    "    utc = True\n",
    ")\n",
    "\n",
    "cyclicf = CyclicalFeatures(\n",
    "    variables=[\"hour\", \"month\", \"day_of_year\"],\n",
    "    drop_original= True\n",
    ")\n",
    "\n",
    "fourierf = AddFourierFeatures(\n",
    "    K = 1,\n",
    "    periods=[horizon, horizon*2],\n",
    "    by = \"hour\"\n",
    ")\n",
    "\n",
    "lagf = LagFeatures(\n",
    "    variables=\"value_corrected\",\n",
    "    periods=list(range(1,horizon+1)),\n",
    "    missing_values = \"ignore\"\n",
    ")\n",
    "\n",
    "windf24 = WindowFeatures(\n",
    "    variables=\"value_corrected\",\n",
    "    functions=[\"mean\"],\n",
    "    window=[int(horizon/2), horizon],\n",
    "    freq=\"1H\",\n",
    "    missing_values=\"ignore\"\n",
    ")\n",
    "\n",
    "imputer = DropMissingData()\n",
    "\n",
    "drop_features = DropFeatures(features_to_drop=[\"value_corrected\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_pipeline = Pipeline([\n",
    "    (\"datetime features\", dtf),\n",
    "    (\"cyclical features\", cyclicf),\n",
    "    (\"fourier features\", fourierf),\n",
    "    (\"lag features\", lagf),\n",
    "    (\"window features 24H\", windf24),\n",
    "    (\"imputer\", imputer),\n",
    "    (\"drop features\", drop_features)\n",
    "])\n",
    "\n",
    "centrales = X_train.index.get_level_values(1).unique()\n",
    "X_train_t_list = list()\n",
    "X_test_t_list = list()\n",
    "for cen in centrales:\n",
    "    emb_df = X_train[X_train.index.get_level_values(1) == cen]\n",
    "    emb_df = emb_df.reset_index(level=1)\n",
    "    emb_df_t = prep_pipeline.fit_transform(emb_df)\n",
    "    emb_df_t = emb_df_t.set_index(\"nombre_embalse\", append=True)\n",
    "    X_train_t_list.append(emb_df_t)\n",
    "    \n",
    "    emb_test = X_test[X_test.index.get_level_values(1) == cen]\n",
    "    emb_test = emb_test.reset_index(level=1)\n",
    "    emb_test_t = prep_pipeline.transform(emb_test)\n",
    "    emb_test_t = emb_test_t.set_index(\"nombre_embalse\", append=True)\n",
    "    X_test_t_list.append(emb_test_t)\n",
    "\n",
    "X_train_t = pd.concat(X_train_t_list, axis = 0)\n",
    "X_test_t = pd.concat(X_test_t_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align\n",
    "y_train_t = y_train.loc[X_train_t.index]\n",
    "y_test_t = y_test.loc[X_test_t.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reservoir_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7029e492f706b46c67808507ecd16dab067c027a9d2a27caa4dd225e273ec307"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
